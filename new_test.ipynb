{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.lite.Interpreter(r'models\\hunam_model_float32.tflite')\n",
    "face_detector = cv.FaceDetectorYN.create(r'models\\face_detection_yunet_2023mar.onnx', \"\", (320, 320))\n",
    "model.allocate_tensors()\n",
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp = {'name': 'images', 'index': 0, 'shape': array([  1, 640, 640,   3], dtype=int32), 'shape_signature': array([  1, 640, 640,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "out = {'name': 'Identity', 'index': 1379, 'shape': array([   1,    6, 8400], dtype=int32), 'shape_signature': array([   1,    6, 8400], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n"
     ]
    }
   ],
   "source": [
    "inp_details = model.get_input_details()[0]\n",
    "out_details = model.get_output_details()[0]\n",
    "\n",
    "print(f\"inp = {inp_details}\")\n",
    "print(f\"out = {out_details}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img_path):\n",
    "    img = cv.imread(img_path)\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    img = cv.resize(img, (640, 640))\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    return np.expand_dims(img, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(img_path):\n",
    "    img = preprocess_img(img_path)\n",
    "    print(img.shape)\n",
    "    model.set_tensor(inp_details['index'], img)\n",
    "    model.invoke()\n",
    "    out = model.get_tensor(out_details['index'])\n",
    "    return np.asarray(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 640, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "res = run_inference(r\"C:\\Users\\s9554\\Downloads\\test2_3_human.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_data = np.squeeze(res)\n",
    "fnl = []\n",
    "for i in range(out_data.shape[1]):\n",
    "    if 0.46 <= out_data[4, i] <= 0.47:\n",
    "        x, y, w, h = out_data[: 4, i]\n",
    "        conf = out_data[4, i]\n",
    "        class_id = int(out_data[5, i])\n",
    "        fnl.append([x, y, w, h, conf, class_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[np.float32(0.3391194),\n",
       "  np.float32(0.5349584),\n",
       "  np.float32(0.21574287),\n",
       "  np.float32(0.8599608),\n",
       "  np.float32(0.46323875),\n",
       "  0]]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(output_data, conf_threshold=0.5):\n",
    "    output_data = np.squeeze(output_data)  # Remove batch dimension\n",
    "    boxes = []\n",
    "    for i in range(output_data.shape[1]):\n",
    "        conf = output_data[4, i]  # Confidence score\n",
    "        if conf > conf_threshold:\n",
    "            # Extract bounding box and class\n",
    "            x, y, w, h = output_data[:4, i]\n",
    "            class_id = int(output_data[5, i])\n",
    "            boxes.append([x, y, w, h, conf, class_id])\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = post_process(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sor_box = sorted(boxes, reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(sor_box))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float32(0.6357984),\n",
       " np.float32(0.54204184),\n",
       " np.float32(0.17034161),\n",
       " np.float32(0.7939236),\n",
       " np.float32(0.53402007),\n",
       " 0]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box_high = sor_box[0]\n",
    "box_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_img(img_path, box, conf_thres = 0.4):\n",
    "    image = cv.imread(img_path)\n",
    "    face_img = []\n",
    "    h, w, _ = image.shape  # Original image dimensions\n",
    "\n",
    "    # Denormalize and convert boxes to (x1, y1, x2, y2)\n",
    "    processed_boxes = []\n",
    "    for b in box:\n",
    "        x_center, y_center, width, height, conf, class_id = b\n",
    "        if conf > conf_thres:\n",
    "            x_center *= w\n",
    "            y_center *= h\n",
    "            width *= w\n",
    "            height *= h\n",
    "\n",
    "            # Convert to corner coordinates\n",
    "            x1 = int(x_center - width / 2)\n",
    "            y1 = int(y_center - height / 2)\n",
    "            x2 = int(x_center + width / 2)\n",
    "            y2 = int(y_center + height / 2)\n",
    "\n",
    "            cv.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            img_face = image[y1: y2 , x1: x2]\n",
    "            frame_width = img_face.shape[1]\n",
    "            frame_height = img_face.shape[0]\n",
    "            # if frame_height > 320:\n",
    "            #     crop_h = (frame_height - 320) // 2\n",
    "            #     img_face = img_face[crop_h: crop_h + 320, :]\n",
    "            # if frame_width > 320:\n",
    "            #     crop_w = (frame_width - 320) // 2\n",
    "            #     img_face = img_face[:, crop_w: crop_w + 320]\n",
    "            pad_h = max(0, 320 - frame_height)\n",
    "            pad_w = max(0, 320 - frame_width)\n",
    "            padded_img = np.pad(img_face, (\n",
    "                (pad_h // 2, pad_h - pad_h // 2),\n",
    "                (pad_w //2, pad_w - pad_w // 2),\n",
    "                (0, 0)),\n",
    "                mode = 'constant',\n",
    "                constant_values = 0)\n",
    "            ph = padded_img.shape[0]\n",
    "            pw = padded_img.shape[1]\n",
    "            print(padded_img.shape)\n",
    "            print(pw)\n",
    "            print(ph)\n",
    "            face_detector.setInputSize((pw, ph))\n",
    "            _, face = face_detector.detect(padded_img)\n",
    "            # face_img.append(padded_img)\n",
    "            for f in face:\n",
    "                bbox = f[:4].astype(int)\n",
    "                x1, y1, width, height = bbox\n",
    "                x2, y2 = x1 + width, y1 + height\n",
    "                cv.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv.putText(image, f\"Conf: {conf:.2f}\", (x1, y1 - 10),\n",
    "            cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    cv.imshow(\"NMS Results\", image)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "    return face_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(324, 320, 3)\n",
      "320\n",
      "324\n",
      "(320, 320, 3)\n",
      "320\n",
      "320\n",
      "(320, 320, 3)\n",
      "320\n",
      "320\n",
      "(351, 320, 3)\n",
      "320\n",
      "351\n",
      "(347, 320, 3)\n",
      "320\n",
      "347\n"
     ]
    }
   ],
   "source": [
    "faces = draw_img(r\"C:\\Users\\s9554\\Downloads\\test2_3_human.jpg\", sor_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "face = np.asarray(faces)\n",
    "print(face.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(b1, b2):\n",
    "    x1, y1, x2, y2 = b1\n",
    "    x3, y3, x4, y4 = b2\n",
    "\n",
    "    x_iter1 = max(x1, x3)\n",
    "    y_ter1 = max(y1, y3)\n",
    "    x_iter2 = min(x2, x4)\n",
    "    y_iter2 = min(y1, y4)\n",
    "\n",
    "    width_iter = abs(x_iter2 - x_iter1)\n",
    "    height_iter = abs(y_iter2 - y_ter1)\n",
    "    area_iter = width_iter * height_iter\n",
    "\n",
    "    width_box1 = abs(x2 - x1)\n",
    "    height_box1 = abs(y2 - y1)\n",
    "    width_box2 = abs(x4 - x3)\n",
    "    height_box2 = abs(y4 - y3)\n",
    "\n",
    "    area_box1 = width_box1 * height_box1\n",
    "    area_box2 = width_box2 * height_box2\n",
    "\n",
    "    area_union = area_box2 + area_box1 - area_iter\n",
    "    iou = area_iter / area_union\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_supression(boxes, iou_thres = 0.5):\n",
    "    boxes = sorted(boxes, key = lambda x: x[4], reverse = True)\n",
    "    selected_box = []\n",
    "\n",
    "    while boxes:\n",
    "        chosen_box = boxes.pop(0)\n",
    "        selected_box.append(chosen_box)\n",
    "\n",
    "        # Remove boxes with high overlap (IoU threshold)\n",
    "        boxes = [box for box in boxes if iou(chosen_box[:4], box[:4]) < iou_thres]\n",
    "\n",
    "    return selected_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes_with_nms(image_path, boxes, conf_threshold=0.5):\n",
    "    # Load the image\n",
    "    image = cv.imread(image_path)\n",
    "    h, w, _ = image.shape  # Original image dimensions\n",
    "\n",
    "    # Denormalize and convert boxes to (x1, y1, x2, y2)\n",
    "    processed_boxes = []\n",
    "    for box in boxes:\n",
    "        x_center, y_center, width, height, conf, class_id = box\n",
    "        if conf > conf_threshold:\n",
    "            x_center *= w\n",
    "            y_center *= h\n",
    "            width *= w\n",
    "            height *= h\n",
    "\n",
    "            # Convert to corner coordinates\n",
    "            x1 = int(x_center - width / 2)\n",
    "            y1 = int(y_center - height / 2)\n",
    "            x2 = int(x_center + width / 2)\n",
    "            y2 = int(y_center + height / 2)\n",
    "            processed_boxes.append([x1, y1, x2, y2, conf, class_id])\n",
    "\n",
    "    # Apply Non-Maximum Suppression (NMS)\n",
    "    nms_boxes = non_max_supression(processed_boxes)\n",
    "\n",
    "    # Draw final boxes after NMS\n",
    "    for box in nms_boxes:\n",
    "        x1, y1, x2, y2, conf, class_id = box\n",
    "        cv.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv.putText(image, f\"Conf: {conf:.2f}\", (x1, y1 - 10),\n",
    "                    cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the image\n",
    "    cv.imshow(\"NMS Results\", image)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_boxes_with_nms(r\"C:\\Users\\s9554\\Downloads\\test2_3_human.jpg\", boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
